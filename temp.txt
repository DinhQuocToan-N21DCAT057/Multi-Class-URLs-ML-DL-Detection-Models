!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow keras torch nltk joblib pydot torchviz torchinfo

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import re
import seaborn as sns
import joblib

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras import Sequential
from tensorflow.keras.utils import plot_model, to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler
from sklearn.metrics import f1_score, precision_recall_curve, auc, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

df = pd.read_csv('/content/drive/MyDrive/TTTN-Dataset/balanced_dataset_1.csv')
df.head(10)

	url	url_len	hostname_len	entropy	nb_dots	nb_hyphens	nb_exclamation	nb_and	nb_equal	nb_underscore	...	percent_ex_media	percent_safe_anchor	percent_in_links	whois_reg_domain	domain_reg_len	domain_age	dns_record	google_index	page_rank	label
0	http://www.goebcomputer.de/index.php?option=co...	85	19	-4.551858	3	0	1	3	4	1	...	0.0	0.0	0.0	0	0	-2	0	-1	0	defacement
1	http://www.onestoprecycling.co.uk/index.php?op...	91	26	-4.619352	4	0	1	3	4	1	...	0.0	0.0	0.0	0	169	6039	0	-1	2	defacement
2	http://116.113.182.195:58245/Mozi.m	35	15	-3.957296	4	0	0	0	0	0	...	0.0	0.0	0.0	1	0	-2	1	-1	0	malware
3	https://pacovilla.com/?p=52334	30	13	-4.189898	1	0	1	0	1	0	...	0.0	0.0	0.0	0	26	1799	0	-1	3	benign
4	https://genforum.genealogy.com/mcshane/page2.html	49	22	-4.142486	3	0	0	0	0	0	...	0.0	0.0	0.0	0	206	9655	0	-1	5	benign
5	https://www.engr.du.edu/profile/marvin.htm	42	15	-4.225185	4	0	0	0	0	0	...	0.0	0.0	0.0	0	744	13656	0	-1	5	phishing
6	https://2online.tv/tele-quebec/	31	10	-3.934530	1	1	0	0	0	0	...	0.0	0.0	0.0	1	0	-2	1	-1	0	benign
7	http://www.sciclubmarzocco.it/index.html?optio...	121	22	-4.698126	3	1	1	5	6	1	...	0.0	0.0	0.0	0	0	-2	1	-1	0	defacement
8	https://lumennex.pro/downloads/Lumen.rar	40	12	-4.115312	2	0	0	0	0	0	...	0.0	0.0	0.0	0	290	74	1	-1	0	malware
9	http://114.228.141.191:38264/Mozi.m	35	15	-3.878585	4	0	0	0	0	0	...	0.0	0.0	0.0	1	0	-2	1	-1	0	malware
10 rows × 73 columns

# Preprocess labels
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(df['label'])
labels_one_hot = tf.keras.utils.to_categorical(labels_encoded)
label_names = label_encoder.classes_

X1 = df.drop(columns=['label', 'url'])
X1.shape #(385260, 71)

# MinMaxScaler except for these columns
columns_to_scale = [col for col in X1.columns if col not in ['domain_reg_len', 'domain_age', 'page_rank', 'google_index']]
scaler = MinMaxScaler(feature_range=(0, 1))
X1[columns_to_scale] = scaler.fit_transform(X1[columns_to_scale])
joblib.dump(scaler, 'scaler.pkl') #Download for predict
X1.head(10)

url_len	hostname_len	entropy	nb_dots	nb_hyphens	nb_exclamation	nb_and	nb_equal	nb_underscore	nb_tilde	...	percent_in_media	percent_ex_media	percent_safe_anchor	percent_in_links	whois_reg_domain	domain_reg_len	domain_age	dns_record	google_index	page_rank
0	0.042397	0.072650	0.377669	0.071429	0.000000	0.066667	0.06	0.078431	0.02381	0.0	...	0.0	0.0	0.0	0.0	0.0	0	-2	0.0	-1	0
1	0.045789	0.102564	0.360328	0.095238	0.000000	0.066667	0.06	0.078431	0.02381	0.0	...	0.0	0.0	0.0	0.0	0.0	169	6039	0.0	-1	2
2	0.014132	0.055556	0.530432	0.095238	0.000000	0.000000	0.00	0.000000	0.00000	0.0	...	0.0	0.0	0.0	0.0	1.0	0	-2	1.0	-1	0
3	0.011306	0.047009	0.470669	0.023810	0.000000	0.066667	0.00	0.019608	0.00000	0.0	...	0.0	0.0	0.0	0.0	0.0	26	1799	0.0	-1	3
4	0.022046	0.085470	0.482851	0.071429	0.000000	0.000000	0.00	0.000000	0.00000	0.0	...	0.0	0.0	0.0	0.0	0.0	206	9655	0.0	-1	5
5	0.018089	0.055556	0.461602	0.095238	0.000000	0.000000	0.00	0.000000	0.00000	0.0	...	0.0	0.0	0.0	0.0	0.0	744	13656	0.0	-1	5
6	0.011871	0.034188	0.536281	0.023810	0.015625	0.000000	0.00	0.000000	0.00000	0.0	...	0.0	0.0	0.0	0.0	1.0	0	-2	1.0	-1	0
7	0.062747	0.085470	0.340088	0.071429	0.015625	0.066667	0.10	0.117647	0.02381	0.0	...	0.0	0.0	0.0	0.0	0.0	0	-2	1.0	-1	0
8	0.016959	0.042735	0.489833	0.047619	0.000000	0.000000	0.00	0.000000	0.00000	0.0	...	0.0	0.0	0.0	0.0	0.0	290	74	1.0	-1	0
9	0.014132	0.055556	0.550656	0.095238	0.000000	0.000000	0.00	0.000000	0.00000	0.0	...	0.0	0.0	0.0	0.0	1.0	0	-2	1.0	-1	0
10 rows × 71 columns

Y1 = pd.DataFrame(labels_one_hot, columns=label_encoder.classes_)
Y1.to_csv('/content/drive/MyDrive/TTTN-Dataset/labels_one_hot.csv', index=False)
Y1.shape #(385260, 4)

X2 = df['url']
X2.head(2)

X3 = df.drop(columns=['label', 'url'])
Y3 = pd.read_csv('/content/drive/MyDrive/TTTN-Dataset/labels_one_hot.csv')
Y3 = np.argmax(Y3.values, axis=1)
X_train3,X_test3,Y_train3,Y_test3 = train_test_split(X3,Y3,stratify = Y3,test_size = 0.2,random_state = 42)
print(X_train3.shape,Y_train3.shape)
print(X_test3.shape,Y_test3.shape)

(308208, 71) (308208,)
(77052, 71) (77052,)

def conf_matrix_multi_label_RF(X_test, y_test, model, label_names):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)
    disp.plot(cmap=plt.cm.YlGn)
    plt.title('CONFUSION MATRIX (Random Forest)')
    plt.show()
    f1 = f1_score(y_test, y_pred, average='macro')
    print(f"Macro F1-Score: {f1:.4f}")

def pr_auc_multi_class_RF(X_test, y_test, model, label_names):
    y_pred_proba = model.predict_proba(X_test)  # Shape: (n_samples, n_classes)
    y_test_one_hot = np.eye(len(label_names))[y_test]  # Chuyển y_test sang one-hot
    n_classes = len(label_names)
    plt.figure(figsize=(14, 7))
    pr_aucs = []
    for i in range(n_classes):
        precision, recall, _ = precision_recall_curve(y_test_one_hot[:, i], y_pred_proba[:, i])
        pr_auc = auc(recall, precision)
        pr_aucs.append(pr_auc)
        plt.plot(recall, precision, label=f'{label_names[i]} (PR-AUC = {pr_auc:.2f})')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('PRECISION-RECALL CURVES FOR MULTI-CLASS CLASSIFICATION (Random Forest)')
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()
    macro_pr_auc = np.mean(pr_aucs)
    print(f"Macro PR-AUC: {macro_pr_auc:.4f}")

# Kiểm tra phân bố nhãn
print("Phân bố nhãn (tỷ lệ):", pd.Series(Y3).value_counts(normalize=True))

RF = RandomForestClassifier(
  n_estimators=100,
  max_depth=15,
  min_samples_split=5,
  min_samples_leaf=1,
  max_features='sqrt',
  bootstrap=True,
  n_jobs=-1,
  random_state=42
)

Phân bố nhãn (tỷ lệ): 0    0.274521
1    0.245943
3    0.243506
2    0.236030

# Create DMatrix for XGBoost
dtrain = xgb.DMatrix(X_train3, label=Y_train3)
dval = xgb.DMatrix(X_test3, label=Y_test3)

evals_result = {}
XGB.fit(
    X_train3,
    Y_train3,
    eval_set=[(X_test3, Y_test3)],
    eval_metric=['mlogloss', 'merror'],  # Multi-class log loss and error rate
    verbose=False,
    callbacks=[xgb.callback.EvaluationMonitor(period=1)]
)

RF.fit(X_train3, Y_train3)

label_names = ['benign', 'defacement', 'malware', 'phishing']
conf_matrix_multi_label_RF(X_test3, Y_test3, RF, label_names)